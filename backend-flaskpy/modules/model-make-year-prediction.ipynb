{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Imports**"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-19T22:38:43.413714Z","iopub.status.busy":"2024-04-19T22:38:43.412900Z","iopub.status.idle":"2024-04-19T22:38:50.989339Z","shell.execute_reply":"2024-04-19T22:38:50.988587Z","shell.execute_reply.started":"2024-04-19T22:38:43.413677Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","import os\n","import PIL.Image as Image\n","from IPython.display import display\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["# **Global Variables**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T22:38:53.851237Z","iopub.status.busy":"2024-04-19T22:38:53.850028Z","iopub.status.idle":"2024-04-19T22:38:53.855073Z","shell.execute_reply":"2024-04-19T22:38:53.854161Z","shell.execute_reply.started":"2024-04-19T22:38:53.851204Z"},"trusted":true},"outputs":[],"source":["dataset_path = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data'\n","image_size = (400, 400)"]},{"cell_type":"markdown","metadata":{},"source":["# **Preprocessing**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T22:38:54.730162Z","iopub.status.busy":"2024-04-19T22:38:54.729244Z","iopub.status.idle":"2024-04-19T22:39:00.576286Z","shell.execute_reply":"2024-04-19T22:39:00.575460Z","shell.execute_reply.started":"2024-04-19T22:38:54.730115Z"},"trusted":true},"outputs":[],"source":["train_tfms = transforms.Compose([transforms.Resize(image_size),\n","                                transforms.RandomHorizontalFlip(),\n","                                transforms.RandomRotation(15),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","test_tfms = transforms.Compose([transforms.Resize(image_size),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","test_time_tfms = transforms.Compose([transforms.Resize(image_size),\n","                                transforms.ToTensor(),\n","                                transforms.RandomRotation(90),\n","                                transforms.RandomHorizontalFlip(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","\n","train_dataset = torchvision.datasets.ImageFolder(root=os.path.join(dataset_path, 'train'), transform = train_tfms)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle=True, num_workers = 2)\n","\n","test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform = test_tfms)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle=False, num_workers = 2)"]},{"cell_type":"markdown","metadata":{},"source":["# **ResNet Model**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T22:39:00.578727Z","iopub.status.busy":"2024-04-19T22:39:00.577978Z","iopub.status.idle":"2024-04-19T22:39:01.928078Z","shell.execute_reply":"2024-04-19T22:39:01.927341Z","shell.execute_reply.started":"2024-04-19T22:39:00.578693Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n","100%|██████████| 83.3M/83.3M [00:00<00:00, 150MB/s] \n"]}],"source":["# i will use pretrained model for more accurcy\n","res_model = models.resnet34(pretrained=True)\n","num_ftrs = res_model.fc.in_features\n","num_classes = len(train_dataset.classes)\n","\n","res_model.fc = nn.Linear(num_ftrs, num_classes)\n","res_model = res_model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(res_model.parameters(), lr=0.01, momentum=0.9)\n","\n","# to get more acc we will tracking learning rate \n","lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T22:39:04.512232Z","iopub.status.busy":"2024-04-19T22:39:04.511864Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Train Loss: 3.9779, Val Loss: 2.6616, Val Accuracy: 0.2996\n","Epoch 2/10, Train Loss: 1.6344, Val Loss: 1.6936, Val Accuracy: 0.5415\n","Epoch 3/10, Train Loss: 0.8619, Val Loss: 1.2549, Val Accuracy: 0.6432\n"]}],"source":["epochs = 10  \n","\n","train_losses = []\n","val_losses = []\n","accuracies = []\n","\n","for epoch in range(epochs):\n","    # Training loop\n","    res_model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = res_model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item() * inputs.size(0)\n","    \n","    train_loss = running_loss / len(train_dataset)\n","    train_losses.append(train_loss)\n","    \n","    res_model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = res_model(inputs)\n","            loss = criterion(outputs, labels)\n","            \n","            val_loss += loss.item() * inputs.size(0)\n","            \n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    val_loss = val_loss / len(test_dataset)\n","    val_losses.append(val_loss)\n","    accuracy = correct / total\n","    accuracies.append(accuracy)\n","    \n","\n","    print(f'Epoch {epoch+1}/{epochs}, '\n","          f'Train Loss: {train_loss:.4f}, '\n","          f'Val Loss: {val_loss:.4f}, '\n","          f'Val Accuracy: {accuracy:.4f}')\n","    \n","\n","    lrscheduler.step(accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plotting the results\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n","plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(range(1, epochs + 1), accuracies, label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Validation Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# save model \n","torch.save(res_model.state_dict(), 'resnet_model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["# **Load and Prediction**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["loaded_model = models.resnet34(pretrained=False) \n","loaded_model.fc = nn.Linear(loaded_model.fc.in_features, num_classes) \n","loaded_model.load_state_dict(torch.load('resnet_model.pth'))\n","loaded_model.eval() \n","\n","def preprocess_image(image_path):\n","    transform = transforms.Compose([\n","        transforms.Resize((400, 400)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","    image = Image.open(image_path)\n","    image = transform(image).unsqueeze(0)\n","    return image\n","\n","image_path = '/kaggle/input/test-data/Acura_ILX_2013_28_16_110_15_4_70_55_179_39_FWD_5_4_4dr_UMh.jpg'\n","input_image = preprocess_image(image_path)\n","\n","with torch.no_grad():\n","    output = loaded_model(input_image)\n","    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","    predicted_class = torch.argmax(probabilities).item()\n","\n","class_labels = train_dataset.classes\n","predicted_label = class_labels[predicted_class]\n","\n","print(f\"Predicted class: {predicted_label}\")"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":31559,"sourceId":46697,"sourceType":"datasetVersion"},{"datasetId":4834430,"sourceId":8169252,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
